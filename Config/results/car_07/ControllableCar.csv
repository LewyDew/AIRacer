Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,64.3896103896104,-1.1011431,4.956578935447492,4.956578935447492,1.0
20000,1.4189383,67.54482758620689,-0.9209516,7.988356084039767,7.988356084039767,1.0
30000,1.4203192,63.506410256410255,0.05120658,4.201935466643302,4.201935466643302,1.0
40000,1.4204147,65.80405405405405,0.009005105,5.73466659228007,5.73466659228007,1.0
50000,1.4201663,66.46979865771812,0.4029961,5.808108094576243,5.808108094576243,1.0
60000,1.4201279,63.35897435897436,0.35044655,4.889743581796304,4.889743581796304,1.0
70000,1.4194639,62.87179487179487,0.48543176,6.1339742587162895,6.1339742587162895,1.0
80000,1.419319,64.47712418300654,0.47951588,6.922875681733774,6.922875681733774,1.0
90000,1.4184961,64.05194805194805,0.61518806,4.248701343288669,4.248701343288669,1.0
100000,1.4182237,63.50322580645161,0.69013387,6.1580646238019385,6.1580646238019385,1.0
110000,1.4182144,65.5,0.7473225,8.409333194096883,8.409333194096883,1.0
120000,1.4182147,66.41610738255034,0.7971658,11.314864728901837,11.314864728901837,1.0
