Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,114.73563218390805,-3.3193538,-8.174418604651162,-8.174418604651162,1.0
20000,1.4189383,116.28235294117647,-3.475083,-5.8,-5.8,1.0
30000,1.4160225,113.06818181818181,-3.4332328,-2.5738636363636362,-2.5738636363636362,1.0
40000,1.4156997,115.90361445783132,-3.2290108,-5.755952380952381,-5.755952380952381,1.0
50000,1.4134603,117.38636363636364,-3.3294342,3.5352941176470587,3.5352941176470587,1.0
60000,1.41312,117.01204819277109,-3.1641366,-3.558139534883721,-3.558139534883721,1.0
70000,1.41145,115.44827586206897,-3.0656424,-8.186046511627907,-8.186046511627907,1.0
80000,1.4110342,114.45882352941176,-3.3194268,-3.4705882352941178,-3.4705882352941178,1.0
90000,1.4111551,116.67441860465117,-3.2856474,3.4302325581395348,3.4302325581395348,1.0
100000,1.4112016,118.76315789473684,-2.926052,7.681818181818182,7.681818181818182,1.0
110000,1.4115237,127.87951807228916,-3.0946584,-5.439024390243903,-5.439024390243903,1.0
